<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css"/>
    <title>essentia.js example</title>
  </head>
      <body style="background-color:  #000000!important;"">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>
        <script src="../../../dist/essentia-wasm.web.js"></script>
        <script src="../../../dist/essentia.js-core.js"></script>
        <script src="../../../dist/essentia.js-plot.js"></script>
        <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
        
        <div class="ui main_wrapper landing-image">

        <div class="ui header centered" id="header">
          <a href="/examples/">
            <img id="header-img" src="../../../src/assets/img/essentiajsbanner.png">
          </a>
          <div>
              <h2 class="ui header white-text" style="color: azure;">PitchYinProbabilistic extraction with Web Audio API (ScriptNodeProcessor)</h2>
          </div>

          <div class="ui divider" style="height: 2px; width: 1px;"></div>

          <div class="ui basic large button">
            <a href="https://github.com/MTG/essentia.js/tree/master/examples/script-node-processor" target="_blank" class="ui small button">Code<i class="right github icon"></i></a>
          </div>

        </div>
        
        <div class="body-container">

          <div class="ui centered one column grid container">
            <div class="ui vertical buttons row">
              <center><button id="recordButton" class="ui red inverted big button record-button">Mic
                  &nbsp;&nbsp;<i class="microphone icon"></i></button></center>
            </div>

            <div id="plotDiv" class="ui centered segment" style="width: 650px; height: 300px; background-color: transparent"></div>

          </div>

        </div>
        
        <center>
        <div class="footer" style="margin-top: 30px; height: 20%;">
          <a class="demo_logo" target="_blank" href="//essentia.upf.edu">
            <img id="logo" src="https://essentia.upf.edu/documentation/_static/essentia_logo.svg" alt="MTG Logo"
              style="margin-left: 40px; height: 70px;">
          </a>
          <a target="_blank" href="https://www.upf.edu/web/mtg">
            <img class="essnt-footer_mtg-logo" src="https://mtg.github.io/assets/img/upflogo.png" alt="mtg logo"
                style="width:300px; height: 70px;">
          </a>
        </div>
        </center>
      
        <script>
            // global var to load essentia instance from wasm build
            let essentia;
            let isEssentiaInstance = false;
            // global var for web audio api AudioContext
            let audioCtx;
            // buffer size microphone stream (bufferSize is high in order to make PitchYinProbabilistic algo to work)
            let bufferSize = 8192;

            try {
              const AudioContext = window.AudioContext || window.webkitAudioContext;
              audioCtx = new AudioContext();
              } 
            catch (e) {
              throw 'Could not instantiate AudioContext: ' + e.message;
            }

            // global var getUserMedia mic stream
            let gumStream;
            
            // settings for plotting
            let plotContainerId = "plotDiv";
            let plotMelodyContour = new EssentiaPlot.PlotMelodyContour(Plotly, plotContainerId);


            // record native microphone input and do further audio processing on each audio buffer using the given callback functions
            function startMicRecordStream(audioCtx, bufferSize, onProcessCallback, btnCallback) {
              // cross-browser support for getUserMedia
              navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || 
                                        navigator.mozGetUserMedia || navigator.msGetUserMedia;           
              window.URL = window.URL || window.webkitURL || window.mozURL || window.msURL

              if (navigator.getUserMedia) {
                console.log('Initializing audio...')
                navigator.getUserMedia({audio: true, video: false}, function(stream) {
                  gumStream = stream;
                  if (gumStream.active) {
                    console.log('Audio context sample rate = ' + audioCtx.sampleRate);
                    var mic = audioCtx.createMediaStreamSource(stream);
                    // We need the buffer size that is a power of two 
                    if ((bufferSize % 2) != 0 || bufferSize < 4096) {
                      throw "Choose a buffer size that is a power of two and greater than 4096"
                    };
                    // In most platforms where the sample rate is 44.1 kHz or 48 kHz, 
                    // and the default bufferSize will be 4096, giving 10-12 updates/sec.
                    console.log('Buffer size = ' + bufferSize);
                    if (audioCtx.state == 'suspended') {
                      audioCtx.resume();
                    }
                    const scriptNode = audioCtx.createScriptProcessor(bufferSize, 1, 1);
                    // onprocess callback (here we can use essentia.js algos)
                    scriptNode.onaudioprocess = onProcessCallback;
                    // It seems necessary to connect the stream to a sink for the pipeline to work, contrary to documentataions.
                    // As a workaround, here we create a gain node with zero gain, and connect temp to the system audio output.
                    const gain = audioCtx.createGain();
                    gain.gain.setValueAtTime(0, audioCtx.currentTime);
                    mic.connect(scriptNode);
                    scriptNode.connect(gain);
                    gain.connect(audioCtx.destination);

                    if (btnCallback) { btnCallback() };
                  } else {throw 'Mic stream not active';}
                }, function(message) {
                  throw 'Could not access microphone - ' + message;
                });
              } else {throw 'Could not access microphone - getUserMedia not available';};
            }


            function stopMicRecordStream() {
              console.log("Stopped recording ...");
              // stop mic stream 
              gumStream.getAudioTracks().forEach(function(track) {
                track.stop();
              });
              $("#recordButton").removeClass('recording');
              $("#recordButton").html('Mic &nbsp;&nbsp;<i class="microphone icon"></i>');
              isPlotting = false;
              audioCtx.suspend();
              plotMelodyContour.destroy();
            }

            // ScriptNodeProcessor callback function to extract pitchyin feature using essentia.js and plotting it on the front-end
            function onRecordEssentiaFeatureExtractor(event) {
              // convert the float32 audio data into std::vector<float> for using essentia algos 
              var bufferSignal = essentia.arrayToVector(event.inputBuffer.getChannelData(0));
              if (!bufferSignal) { throw "onRecordingError: empty audio signal input found!"};
              
              // check https://essentia.upf.edu/reference/std_PitchYinProbabilistic.html
              var algoOutput = essentia.PitchYinProbabilistic(bufferSignal, // input_1
                                                            // parameters (optional)
                                                            4096, // frameSize
                                                            256, // hopSize
                                                            0.1, // lowRMSThreshold
                                                            'zero', // outputUnvoiced,
                                                            false, // preciseTime
                                                            audioCtx.sampleRate); //sampleRate

              // convert the output to js arrray
              var pitchValues = essentia.vectorToArray(algoOutput.pitch);
              // here we call the plotting function to display realtime feature extraction results
              plotMelodyContour.create(pitchValues, 'PitchYinProbabilistic', bufferSize, audioCtx.sampleRate);
              // free the outputs
              delete algoOutput;
            }
      
            $(document).ready(function () {
              // add event listeners to ui objects
              $('#recordButton').click(function () {
                var recording = $(this).hasClass('recording');
                if (!recording) {
                  $(this).prop("disabled", true);

                  EssentiaModule().then( function(essentiaModule){

                    if (!isEssentiaInstance) { 
                      essentia = new Essentia(essentiaModule); 
                      isEssentiaInstance = true; 
                    }
                    // 
                    startMicRecordStream(audioCtx, bufferSize, onRecordEssentiaFeatureExtractor, function() {
                      // called when the promise fulfilled
                      $('#recordButton').addClass('recording');
                      $('#recordButton').html('Stop &nbsp;&nbsp;<i class="stop icon"></i>');
                      $('#recordButton').prop("disabled", false);
                    });
                  });
                } else {
                    stopMicRecordStream();
                }
              }); // end recordButton onClick
                
            });
        </script>
      </body>
</html>