<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <link
      rel="stylesheet"
      type="text/css"
      href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css"
    />
    <title>essentia.js with Web Audio API ScriptNodeProcessor example</title>
  </head>
  <body style="background-color:  #000000!important;">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/essentia.js@0.0.9/dist/essentia-wasm.web.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/essentia.js@0.0.9/dist/essentia.js-extractor.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/essentia.js@0.0.9/dist/essentia.js-plot.js"></script>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

    <div class="ui main_wrapper landing-image">
      <div class="ui header centered" id="header">
        <a href="index.html">
          <img
            id="header-img"
            src="https://github.com/MTG/essentia.js/blob/master/src/assets/img/essentiajsbanner.png?raw=true"
          />
        </a>
        <div>
          <h2 class="ui header white-text" style="color: azure;">
            Mel Spectrogram extraction using Web Audio API (ScriptNodeProcessor)
          </h2>
          <div class="ui basic large button">
            <a href="https://github.com/MTG/essentia.js/tree/master/examples/realtime/melspectrogram/example.html" target="_blank" class="ui small button">Code<i class="right github icon"></i></a>
          </div>
        </div>


      <div class="ui divider" style="height: 5px; width: 2px;"></div>
        
      <div class="body-container">
        <div class="ui centered one column grid container">
          <div class="ui vertical buttons row">
            <center>
              <button
                id="recordButton"
                class="ui red inverted big button record-button"
              >
                Mic &nbsp;&nbsp;<i class="microphone icon"></i>
              </button>
            </center>
          </div>

          <div
            id="plotDiv"
            class="ui centered segment"
            style="width: 650px; height: 300px; background-color: transparent"
          ></div>
        </div>
      </div>

      <div class="ui divider" style="height: 50px;"></div>

      <center>
        <div class="footer" style="margin-top: 30px; height: 20%;">
          <a class="demo_logo" target="_blank" href="//essentia.upf.edu">
            <img
              id="logo"
              src="https://essentia.upf.edu/documentation/_static/essentia_logo.svg"
              alt="MTG Logo"
              style="margin-left: 40px; height: 70px;"
            />
          </a>
          <a target="_blank" href="https://www.upf.edu/web/mtg">
            <img
              class="essnt-footer_mtg-logo"
              src="https://mtg.github.io/assets/img/upflogo.png"
              alt="mtg logo"
              style="width:300px; height: 70px;"
            />
          </a>
        </div>
      </center>

      <script>
        // global var to load essentia.js core instance
        let essentiaExtractor;
        let isEssentiaInstance = false;
        // global var for web audio API AudioContext
        let audioCtx;
        // buffer size microphone stream (bufferSize is high in order to make PitchYinProbabilistic algo to work)
        let bufferSize = 2048;

        try {
          const AudioContext = window.AudioContext || window.webkitAudioContext;
          audioCtx = new AudioContext();
        } catch (e) {
          throw "Could not instantiate AudioContext: " + e.message;
        }

        // global var getUserMedia mic stream
        let gumStream;

        // settings for plotting
        let plotContainerId = "plotDiv";
        let plotSpectrogram;

        // record native microphone input and do further audio processing on each audio buffer using the given callback functions
        function startMicRecordStream(
          audioCtx,
          bufferSize,
          onProcessCallback,
          btnCallback
        ) {
          // cross-browser support for getUserMedia
          navigator.getUserMedia =
            navigator.getUserMedia ||
            navigator.webkitGetUserMedia ||
            navigator.mozGetUserMedia ||
            navigator.msGetUserMedia;
          window.URL =
            window.URL || window.webkitURL || window.mozURL || window.msURL;

          if (navigator.getUserMedia) {
            console.log("Initializing audio...");
            navigator.getUserMedia(
              { audio: true, video: false },
              function(stream) {
                gumStream = stream;
                if (gumStream.active) {
                  console.log(
                    "Audio context sample rate = " + audioCtx.sampleRate
                  );
                  var mic = audioCtx.createMediaStreamSource(stream);
                 
                  // In most platforms where the sample rate is 44.1 kHz or 48 kHz,
                  // and the default bufferSize will be 4096, giving 10-12 updates/sec.
                  console.log("Buffer size = " + bufferSize);
                  if (audioCtx.state == "suspended") {
                    audioCtx.resume();
                  }
                  const scriptNode = audioCtx.createScriptProcessor(bufferSize, 1, 1);
                  // onprocess callback (here we can use essentia.js algos)
                  scriptNode.onaudioprocess = onProcessCallback;
                  // It seems necessary to connect the stream to a sink for the pipeline to work, contrary to documentataions.
                  // As a workaround, here we create a gain node with zero gain, and connect temp to the system audio output.
                  const gain = audioCtx.createGain();
                  gain.gain.setValueAtTime(0, audioCtx.currentTime);
                  mic.connect(scriptNode);
                  scriptNode.connect(gain);
                  gain.connect(audioCtx.destination);

                  if (btnCallback) {
                    btnCallback();
                  }
                } else {
                  throw "Mic stream not active";
                }
              },
              function(message) {
                throw "Could not access microphone - " + message;
              }
            );
          } else {
            throw "Could not access microphone - getUserMedia not available";
          }
        }

        function stopMicRecordStream() {
          console.log("Stopped recording ...");
          // stop mic stream
          gumStream.getAudioTracks().forEach(function(track) {
            track.stop();
          });
          $("#recordButton").removeClass("recording");
          $("#recordButton").html(
            'Mic &nbsp;&nbsp;<i class="microphone icon"></i>'
          );
          isPlotting = false;
          audioCtx.suspend();
        }

        // ScriptNodeProcessor callback function to extract pitchyin feature using essentia.js and plotting it on the front-end
        function onRecordEssentiaFeatureExtractor(event) {

          let audioBuffer = event.inputBuffer.getChannelData(0);

          // modifying default extractor settings
          essentiaExtractor.frameSize = 1024;
          essentiaExtractor.hopSize = 512;
          // settings specific to an algorithm
          essentiaExtractor.profile.MelBands.numberBands = 96;
          // compute hpcp for overlapping frames of audio
          let spectrogram = essentiaExtractor.melSpectrogram(audioBuffer);
          // here we call the plotting function to display realtime feature extraction results
          plotSpectrogram.create(
            spectrogram,
            "Log-scaled MelSpectrogram",
            bufferSize,
            audioCtx.sampleRate
          );

        //   plotChroma.isPlotting = true;
        }

        $(document).ready(function() {
          // add event listeners to ui objects
          $("#recordButton").click(function() {
            let recording = $(this).hasClass("recording");
            if (!recording) {
              $(this).prop("disabled", true);

              // create essentia plot instance
              plotSpectrogram= new EssentiaPlot.PlotHeatmap(
                Plotly,
                plotContainerId,
                'spectrogram',
                EssentiaPlot.LayoutSpectrogramPlot // layout settings
              );

              // loads the WASM backend and runs the feature extraction
              EssentiaModule().then(function(essentiaModule) {
                if (!isEssentiaInstance) {
                  essentiaExtractor = new EssentiaExtractor(essentiaModule);
                  isEssentiaInstance = true;
                }
                // start microphone stream using getUserMedia
                startMicRecordStream(
                  audioCtx,
                  bufferSize,
                  onRecordEssentiaFeatureExtractor, // essentia.js feature extractor callback function
                  function() {
                    // called when the promise fulfilled
                    $("#recordButton").addClass("recording");
                    $("#recordButton").html(
                      'Stop &nbsp;&nbsp;<i class="stop icon"></i>'
                    );
                    $("#recordButton").prop("disabled", false);
                  }
                );
              });
            } else {
              stopMicRecordStream();
            }
          }); // end recordButton onClick
        });
      </script>
    </div>
  </body>
</html>
