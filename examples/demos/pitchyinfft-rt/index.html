<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width,initial-scale=1" />
        <link
            rel="stylesheet"
            type="text/css"
            href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css"
        />
        <title>Real-time pitch extraction with Essentia.js</title>
    </head>
    <body style="background-color:  #000000!important;">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.9.4/Chart.min.js" integrity="sha512-d9xgZrVZpmmQlfonhQUvTR7lMPtO7NkZMkA0ABN3PHCbKA5nqylQ/yWlFAyY6hYgdF1Qh6nYiuADWwKB4C2WSw==" crossorigin="anonymous"></script>
        
        <div class="ui main_wrapper landing-image">
            <div class="ui header centered" id="header">
                <a href="https://mtg.github.io/essentia.js/" target="_blank">
                    <img
                        id="header-img"
                        src="./images/essentiajsbanner.png"
                    />
                </a>
                <div>
                    <h2 class="ui header white-text" style="color: azure;">
                        Real-time pitch extraction
                    </h2>
                    <div class="ui basic large button">
                        <a href="https://github.com/MTG/essentia.js/tree/dev/examples/pitchmelodia-rt/" target="_blank" class="ui small button">Code<i class="right github icon"></i></a>
                    </div>
                </div>


            <div class="ui divider" style="height: 5px; width: 2px;"></div>
                
            <div class="body-container">
                <div class="ui centered one column grid container">
                    <div class="ui vertical buttons row">
                        <center>
                            <button id="recordButton" class="ui red inverted big button record-button" role="switch">
                                Mic &nbsp;&nbsp;<i class="microphone icon"></i>
                            </button>
                        </center>
                    </div>

                    <canvas
                        id="axesDiv"
                        class="ui centered"
                        style="width: 800px; height: 388px;"
                    ></canvas>
                </div>
            </div>

            <div class="ui divider" style="height: 50px;"></div>

            <center>
                <div class="footer" style="margin-top: 30px; height: 20%;">
                    <a class="demo_logo" target="_blank" href="//essentia.upf.edu">
                        <img
                            id="logo"
                            src="./images/essentia_logo.svg"
                            alt="Essentia logo"
                            style="margin-left: 40px; height: 70px;"
                            crossorigin="anonymous"
                        />
                    </a>
                    <a target="_blank" href="https://www.upf.edu/web/mtg">
                        <img
                            class="essnt-footer_mtg-logo"
                            src="./images/upflogo.png"
                            alt="MTG logo"
                            style="width:300px; height: 70px;"
                        />
                    </a>
                </div>
            </center>
            
            <script>
                exports = {};
            </script>
            <script>
                // From a series of URL to js files, get an object URL that can be loaded in an
                // AudioWorklet. This is useful to be able to use multiple files (utils, data
                // structure, main DSP, etc.) without either using static imports, eval, manual
                // concatenation with or without a build step, etc.
                function URLFromFiles(files) {
                    const promises = files
                        .map((file) => fetch(file)
                        .then((response) => response.text()));

                    return Promise
                        .all(promises)
                        .then((texts) => {
                        texts.unshift("var exports = {};"); // hack to make injected umd modules work
                        const text = texts.join('');
                        const blob = new Blob([text], {type: "application/javascript"});

                        return URL.createObjectURL(blob);
                        });
                }
            </script>
            <script src="https://unpkg.com/ringbuf.js@0.1.0/dist/index.js" crossorigin="anonymous"></script> <!-- by Paul Adenot, repo: https://github.com/padenot/ringbuf.js -->
            <script type="text/javascript" src="resources/chartConfig.js"></script>
            
            <script>
            (function() {
                let bufferSize = 8192;
                // global var getUserMedia mic stream
                let gumStream;
                // global audio node variables
                let mic;
                let pitchNode;
                let analyserNode;
                let pitchBuffer = new Float32Array(4);

                // Shared data with AudioWorkletGlobalScope
                let audioReader;

                // Visualization objects
                let animationId;
                let canvas = document.getElementById("axesDiv");
                let pitchAccum = [];
                let rmsAccum = [];

                // console.log("before chart creation");
                // console.log(RMS_ARRAY);
                // console.log(CONFIDENCE_ARRAY);
                let pitchChart = new Chart(canvas.getContext("2d"), {
                    "data": DATA,
                    "options": OPTIONS
                });
                // console.log("after chart creation");

                // Utils:
                function arraySum(total, num) {
                    return total + num;
                }

                function resetChartData() {
                    rms_pointer = RMS_ARRAY;
                    pitchChart.data.labels = getTimeLabels(NUM_ANALYSIS_FRAMES);
                    pitchChart.data.datasets[0].data = Array(NUM_ANALYSIS_FRAMES).fill(100);
                    pitchChart.data.datasets[1].data = Array(NUM_ANALYSIS_FRAMES).fill(AXES_PITCHES[0]);
                    pitchChart.data.datasets[2].data = Array(NUM_ANALYSIS_FRAMES).fill(AXES_PITCHES.slice(-1)[0]);
                    pitchChart.update();
                }

                function onRecordClickHandler() {
                    let recording = $(this).hasClass("recording");
                    if (!recording) {
                        $(this).prop("disabled", true);
                        
                        resetChartData();
                        // start microphone stream using getUserMedia and runs the feature extraction
                        startMicRecordStream();
                    } else {
                        stopMicRecordStream();
                    }
                }

                // record native microphone input and do further audio processing on each audio buffer using the given callback functions
                function startMicRecordStream() {
                    if (navigator.mediaDevices.getUserMedia) {
                        console.log("Initializing audio...");
                        navigator.mediaDevices.getUserMedia({ audio: true, video: false })
                        .then(startAudioProcessing)
                        .catch(function(message) {
                                throw "Could not access microphone - " + message;
                        });
                    } else {
                        throw "Could not access microphone - getUserMedia not available";
                    }
                }

                function startAudioProcessing(stream) {
                    gumStream = stream;
                    if (gumStream.active) {
                        if (audioCtx.state == "closed") {
                            audioCtx = new AudioContext();
                        }
                        else if (audioCtx.state == "suspended") {
                            audioCtx.resume();
                        }

                        mic = audioCtx.createMediaStreamSource(gumStream);
                        analyserNode = new AnalyserNode(audioCtx, {channelCountMode: "explicit", channelCount: 1, fftSize: 128});

                        let codeForProcessorModule = ["https://cdn.jsdelivr.net/npm/essentia.js@0.1.3/dist/essentia-wasm.umd.js", 
                                                    "https://cdn.jsdelivr.net/npm/essentia.js@0.1.3/dist/essentia.js-core.umd.js", 
                                                    "pitchyinfft-processor.js", 
                                                    "https://unpkg.com/ringbuf.js@0.1.0/dist/index.js"];

                        // inject Essentia.js code into AudioWorkletGlobalScope context, then setup audio graph and start animation
                        URLFromFiles(codeForProcessorModule)
                        .then((concatenatedCode) => {
                            audioCtx.audioWorklet.addModule(concatenatedCode)
                            .then(setupAudioGraph)
                            .catch( function moduleLoadRejected(msg) {
                                console.log(`There was a problem loading the AudioWorklet module code: \n ${msg}`);
                            });
                        })
                        .catch((msg) => {
                            console.log(`There was a problem retrieving the AudioWorklet module code: \n ${msg}`);
                        })

                        // set button to stop
                        $("#recordButton").addClass("recording");
                        $("#recordButton").html('Stop &nbsp;&nbsp;<i class="stop icon"></i>');
                        $("#recordButton").prop("disabled", false);
                    } else {
                        throw "Mic stream not active";
                    }
                }

                function setupAudioGraph() {
                    pitchNode = new AudioWorkletNode(audioCtx, 'pitchyinfft-processor', {
                        processorOptions: {
                            bufferSize: bufferSize,
                            sampleRate: audioCtx.sampleRate,
                        },
                        outputChannelCount: [1]
                    });


                    // It seems necessary to connect the stream to a sink for the pipeline to work, contrary to documentataions.
                    // As a workaround, here we create a analyserNode node with zero analyserNode, and connect temp to the system audio output.
                    mic.connect(pitchNode);
                    pitchNode.connect(analyserNode);

                    requestAnimationFrame(animatePitch); // start plot animation
                }

                let animationStart = 0;
                let elapsed;
                // draw melspectrogram frames
                function animatePitch(timestamp) {
                    // if (animationStart === undefined)

                    animationId = requestAnimationFrame(animatePitch);

                    analyserNode.getFloatTimeDomainData(pitchBuffer);

                    CONFIDENCE_ARRAY.push(pitchBuffer[1]);
                    CONFIDENCE_ARRAY.shift();
                    const logRMS = 1 + Math.log10(pitchBuffer[2] + Number.MIN_VALUE) * 0.5;
                    rmsAccum.push(logRMS);
                    RMS_ARRAY.push(logRMS);
                    RMS_ARRAY.shift();
                    pitchAccum.push(pitchBuffer[0]);
                    pitchChart.data.datasets[0].data.push(pitchBuffer[0]);
                    pitchChart.data.datasets[0].data.shift();

                    // console.info("before chart update");
                    pitchChart.update();
                    // console.info("AFTER chart update");
                }

                function drawFullPitchContour() {
                    rms_pointer = rmsAccum;
                    pitchChart.data.datasets[0].data = pitchAccum;
                    pitchChart.data.datasets[1].data = Array(pitchAccum.length).fill(AXES_PITCHES[0]);
                    pitchChart.data.datasets[2].data = Array(pitchAccum.length).fill(AXES_PITCHES.slice(-1)[0]);
                    pitchChart.data.labels = getTimeLabels(pitchAccum.length);
                    pitchChart.update();
                    pitchAccum = [];
                    rmsAccum = [];
                    console.info("Full pitch contour should be displaying");
                }

                function stopMicRecordStream() {
                    if (animationId) {
                        cancelAnimationFrame(animationId);
                        drawFullPitchContour();
                    }

                    // stop mic stream
                    gumStream.getAudioTracks().forEach(function(track) {
                        track.stop();
                        gumStream.removeTrack(track);
                    });
                    
                    audioCtx.close().then(function() {
                        // manage button state
                        $("#recordButton").removeClass("recording");
                        $("#recordButton").html('Mic &nbsp;&nbsp;<i class="microphone icon"></i>');
                        
                        // disconnect nodes
                        mic.disconnect();
                        pitchNode.disconnect();
                        analyserNode.disconnect();
                        mic = undefined; 
                        pitchNode = undefined; 
                        analyserNode = undefined;

                        console.log("Stopped recording ...");
                    });
                }

                $(document).ready(function() {
                    // check for SharedArrayBuffer support:
                    // add event listeners to ui objects
                    $("#recordButton").on('click', onRecordClickHandler);
                });
            })();
            </script>

        </div>
    </body>
</html>
